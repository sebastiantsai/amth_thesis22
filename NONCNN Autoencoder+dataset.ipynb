{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 170)\n"
     ]
    }
   ],
   "source": [
    "#reading in the data and converting to pandas\n",
    "df = pd.read_csv(r'comscore-activity-unscaled.csv')\n",
    "matrix_df = df.to_numpy()\n",
    "print(matrix_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting to train annd test dataset\n",
    "train, test = train_test_split(matrix_df, test_size=0.05)\n",
    "#obtaining only the first few and not X\n",
    "xtrain = train[:,1:-1]/np.max(train[:,1:-2])\n",
    "xtest = test[:,1:-1]/np.max(test[:,1:-2])\n",
    "x_train = np.reshape(xtrain, (len(xtrain), 7, 24, 1))\n",
    "x_test = np.reshape(xtest, (len(xtest), 7, 24, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the size of our encoded representations\n",
    "encoding_dim = 12 # 7 floats -> compression of factor 24, assuming the input is 24*7 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(168,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "\"\"\"\n",
    "encoded = layers.Dense(160, activation='relu')(input_img)\n",
    "encoded = layers.Dense(150, activation='relu')(encoded)\n",
    "encoded = layers.Dense(140, activation='relu')(encoded)\n",
    "encoded = layers.Dense(130, activation='relu')(encoded)\n",
    "encoded = layers.Dense(120, activation='relu')(encoded)\n",
    "encoded = layers.Dense(110, activation='relu')(encoded)\n",
    "encoded = layers.Dense(90, activation='relu')(encoded)\n",
    "encoded = layers.Dense(70, activation='relu')(encoded)\n",
    "encoded = layers.Dense(50, activation='relu')(encoded)\n",
    "encoded = layers.Dense(30, activation='relu')(encoded)\n",
    "encoded = layers.Dense(15, activation='relu')(encoded)\n",
    "\"\"\"\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "\"\"\"\n",
    "decoded = layers.Dense(15, activation='relu')(encoded)\n",
    "decoded = layers.Dense(30, activation='relu')(decoded)\n",
    "decoded = layers.Dense(50, activation='relu')(decoded)\n",
    "decoded = layers.Dense(70, activation='relu')(decoded)\n",
    "decoded = layers.Dense(90, activation='relu')(decoded)\n",
    "decoded = layers.Dense(100, activation='relu')(decoded)\n",
    "decoded = layers.Dense(110, activation='relu')(decoded)\n",
    "decoded = layers.Dense(120, activation='relu')(decoded)\n",
    "decoded = layers.Dense(130, activation='relu')(decoded)\n",
    "decoded = layers.Dense(140, activation='relu')(decoded)\n",
    "decoded = layers.Dense(150, activation='relu')(decoded)\n",
    "decoded = layers.Dense(160, activation='relu')(decoded)\n",
    "\"\"\"\n",
    "decoded = layers.Dense(168, activation='sigmoid')(encoded)\n",
    "\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 13ms/step - loss: 0.6892 - val_loss: 0.6829\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6788 - val_loss: 0.6660\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6638 - val_loss: 0.6381\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6412 - val_loss: 0.5960\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6091 - val_loss: 0.5440\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5695 - val_loss: 0.4914\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5250 - val_loss: 0.4459\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4797 - val_loss: 0.4089\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4345 - val_loss: 0.3810\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3924 - val_loss: 0.3613\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.3539 - val_loss: 0.3481\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.3206 - val_loss: 0.3401\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2912 - val_loss: 0.3355\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2660 - val_loss: 0.3332\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2447 - val_loss: 0.3329\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2265 - val_loss: 0.3338\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.2108 - val_loss: 0.3350\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1976 - val_loss: 0.3369\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1858 - val_loss: 0.3369\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.1759 - val_loss: 0.3379\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1672 - val_loss: 0.3387\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1595 - val_loss: 0.3383\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.1527 - val_loss: 0.3369\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.1466 - val_loss: 0.3359\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1410 - val_loss: 0.3331\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1360 - val_loss: 0.3318\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1313 - val_loss: 0.3276\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1270 - val_loss: 0.3238\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1230 - val_loss: 0.3181\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1192 - val_loss: 0.3121\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1155 - val_loss: 0.3085\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1121 - val_loss: 0.3029\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1090 - val_loss: 0.2927\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1055 - val_loss: 0.2869\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1025 - val_loss: 0.2786\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0995 - val_loss: 0.2703\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0965 - val_loss: 0.2630\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0938 - val_loss: 0.2540\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0907 - val_loss: 0.2488\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0882 - val_loss: 0.2386\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0853 - val_loss: 0.2311\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0829 - val_loss: 0.2204\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.2104\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0774 - val_loss: 0.2016\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0747 - val_loss: 0.1929\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0723 - val_loss: 0.1793\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.1704\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0670 - val_loss: 0.1573\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0645 - val_loss: 0.1467\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.1385\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0598 - val_loss: 0.1297\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.1249\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0559 - val_loss: 0.1177\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0540 - val_loss: 0.1155\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0528 - val_loss: 0.1134\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.1122\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.1114\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.1106\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.1096\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0485 - val_loss: 0.1088\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0479 - val_loss: 0.1080\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0474 - val_loss: 0.1071\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.1062\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.1054\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.1046\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.1038\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.1031\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.1024\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.1017\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.1011\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.1005\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.1000\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0994\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0990\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0432 - val_loss: 0.0984\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0430 - val_loss: 0.0979\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0977\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.0972\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0424 - val_loss: 0.0967\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0423 - val_loss: 0.0964\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0961\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0420 - val_loss: 0.0958\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.0955\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0953\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0950\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0948\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0414 - val_loss: 0.0946\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0413 - val_loss: 0.0943\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.0942\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0411 - val_loss: 0.0941\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0939\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0409 - val_loss: 0.0938\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0409 - val_loss: 0.0936\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0408 - val_loss: 0.0935\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0407 - val_loss: 0.0934\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0406 - val_loss: 0.0933\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.0932\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0405 - val_loss: 0.0932\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0931\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0404 - val_loss: 0.0930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3abdcfa00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = keras.Model(input_img, encoded)\n",
    "encoded_input = keras.Input(shape = (encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(xtrain, xtrain,\n",
    "                epochs=100,\n",
    "                batch_size = 256,\n",
    "                shuffle=True,\n",
    "                validation_data=(xtest, xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting\n",
    "\n",
    "encoded_imgs = encoder.predict(xtest)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "#encodedimgs = encoder.predict(xtest)\n",
    "#decodedimgs = autoencoder.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 5760x1152 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot predictios v. actual\n",
    "n = 3  # How many we will display\n",
    "plt.figure(figsize=(80, 16))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(xtest[i].reshape(7, 24))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(7, 24))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00792202 0.00676426 0.00647458 0.00550184 0.00607353 0.00462225\n",
      " 0.00359404 0.0045791  0.00442964]\n",
      "[0.0097301  0.00830215 0.00802761 0.00685814 0.00739712 0.00566053\n",
      " 0.00445759 0.00552994 0.00535193]\n"
     ]
    }
   ],
   "source": [
    "print(decoded_imgs[0,1:10])\n",
    "print(decoded_imgs[100, 1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477907, 12)\n",
      "35759\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(r'quant_transactions.csv')\n",
    "matrix_df1 = df1.to_numpy()\n",
    "\n",
    "unique_ids = np.unique(matrix_df1[:,0])\n",
    "print(np.shape(matrix_df1))\n",
    "print(len(unique_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35759, 12)\n"
     ]
    }
   ],
   "source": [
    "#col 1: machine ids\n",
    "#col 2: basket total price\n",
    "#rest of the cols: demographics\n",
    "master_mat = np.empty((len(unique_ids), np.shape(matrix_df1)[1]))\n",
    "\n",
    "for i in range(len(unique_ids)):\n",
    "    indexes = np.where(matrix_df1[:,0] == unique_ids[i])[0]\n",
    "    master_mat[i, 2:np.shape(matrix_df1)[1]] = matrix_df1[indexes[0], 2:np.shape(matrix_df1)[1]]\n",
    "    master_mat[i, 0] = matrix_df1[indexes[0]][0]\n",
    "    basket_tot = 0\n",
    "    for j in range(len(indexes)):\n",
    "        basket_tot += matrix_df1[indexes[j],1]\n",
    "    master_mat[i, 1] = basket_tot\n",
    "print(np.shape(master_mat)) #(35759, 12)\n",
    "\n",
    "master_mat = master_mat[master_mat[:, 0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477907\n",
      "[ 81253085 122850883 123624731 ... 231322828 231323328 231325759]\n",
      "[10]\n",
      "[22]\n",
      "[43]\n",
      "[53]\n",
      "[113]\n",
      "[122]\n",
      "[138]\n",
      "[147]\n",
      "[148]\n",
      "[150]\n",
      "[175]\n",
      "[234]\n",
      "[256]\n",
      "[299]\n",
      "[326]\n",
      "[329]\n",
      "[383]\n",
      "[391]\n",
      "[392]\n",
      "[402]\n",
      "[420]\n",
      "[439]\n",
      "[452]\n",
      "[457]\n",
      "[488]\n",
      "[514]\n",
      "[520]\n",
      "[522]\n",
      "[539]\n",
      "[541]\n",
      "[556]\n",
      "[559]\n",
      "[562]\n",
      "[621]\n",
      "[657]\n",
      "[663]\n",
      "[726]\n",
      "[748]\n",
      "[751]\n",
      "[791]\n",
      "[821]\n",
      "[880]\n",
      "[891]\n",
      "[927]\n",
      "[937]\n",
      "[950]\n",
      "[957]\n",
      "[961]\n",
      "[971]\n",
      "[1018]\n",
      "[1031]\n",
      "[1032]\n",
      "[1059]\n",
      "[1065]\n",
      "[1076]\n",
      "[1077]\n",
      "[1091]\n",
      "[1094]\n",
      "[1098]\n",
      "[1125]\n",
      "[1131]\n",
      "[1192]\n",
      "[1212]\n",
      "[1243]\n",
      "[1279]\n",
      "[1302]\n",
      "[1328]\n",
      "[1392]\n",
      "[1415]\n",
      "[1442]\n",
      "[1455]\n",
      "[1460]\n",
      "[1529]\n",
      "[1583]\n",
      "[1643]\n",
      "[1656]\n",
      "[1716]\n",
      "[1807]\n",
      "[1825]\n",
      "[1905]\n",
      "[1941]\n",
      "[1942]\n",
      "[1958]\n",
      "[1967]\n",
      "[1982]\n",
      "[1984]\n",
      "[2035]\n",
      "[2037]\n",
      "[2040]\n",
      "[2046]\n",
      "[2049]\n",
      "[2070]\n",
      "[2074]\n",
      "[2084]\n",
      "[2102]\n",
      "[2178]\n",
      "[2225]\n",
      "[2235]\n",
      "[2258]\n",
      "[2268]\n",
      "[2283]\n",
      "[2290]\n",
      "[2308]\n",
      "[2347]\n",
      "[2349]\n",
      "[2362]\n",
      "[2377]\n",
      "[2378]\n",
      "[2401]\n",
      "[2406]\n",
      "[2442]\n",
      "[2501]\n",
      "[2507]\n",
      "[2528]\n",
      "[2575]\n",
      "[2591]\n",
      "[2622]\n",
      "[2631]\n",
      "[2678]\n",
      "[2709]\n",
      "[2712]\n",
      "[2722]\n",
      "[2732]\n",
      "[2743]\n",
      "[2756]\n",
      "[2782]\n",
      "[2793]\n",
      "[2808]\n",
      "[2830]\n",
      "[2858]\n",
      "[2861]\n",
      "[2878]\n",
      "[2880]\n",
      "[2887]\n",
      "[2888]\n",
      "[2891]\n",
      "[2934]\n",
      "[2977]\n",
      "[3022]\n",
      "[3037]\n",
      "[3070]\n",
      "[3100]\n",
      "[3110]\n",
      "[3122]\n",
      "[3178]\n",
      "[3287]\n",
      "[3296]\n",
      "[3487]\n",
      "[3528]\n",
      "[3537]\n",
      "[3567]\n",
      "[3600]\n",
      "[3607]\n",
      "[3616]\n",
      "[3669]\n",
      "[3674]\n",
      "[3698]\n",
      "[3727]\n",
      "[3734]\n",
      "[3744]\n",
      "[3767]\n",
      "[3776]\n",
      "[3785]\n",
      "[3811]\n",
      "[3819]\n",
      "[3869]\n",
      "[3891]\n",
      "[3908]\n",
      "[3918]\n",
      "[4004]\n",
      "[4022]\n",
      "[4023]\n",
      "[4065]\n",
      "[4101]\n",
      "[4104]\n",
      "[4119]\n",
      "[4181]\n",
      "[4187]\n",
      "[4222]\n",
      "[4239]\n",
      "[4264]\n",
      "[4295]\n",
      "[4303]\n",
      "[4322]\n",
      "[4351]\n",
      "[4391]\n",
      "[4398]\n",
      "[4405]\n",
      "[4441]\n",
      "[4476]\n",
      "[4491]\n",
      "[4496]\n",
      "[4531]\n",
      "[4532]\n",
      "[4571]\n",
      "[4573]\n",
      "[4581]\n",
      "[4608]\n",
      "[4653]\n",
      "[4690]\n",
      "[4719]\n",
      "[4735]\n",
      "[4744]\n",
      "[4774]\n",
      "[4843]\n",
      "[4846]\n",
      "[4856]\n",
      "[4862]\n",
      "[4883]\n",
      "[4889]\n",
      "[4910]\n",
      "[4976]\n",
      "[4997]\n",
      "[4998]\n",
      "[5001]\n",
      "[5038]\n",
      "[5042]\n",
      "[5089]\n",
      "[5145]\n",
      "[5226]\n",
      "[5238]\n",
      "[5315]\n",
      "[5397]\n",
      "[5414]\n",
      "[5417]\n",
      "[5448]\n",
      "[5461]\n",
      "[5462]\n",
      "[5493]\n",
      "[5505]\n",
      "[5514]\n",
      "[5534]\n",
      "[5582]\n",
      "[5622]\n",
      "[5680]\n",
      "[5689]\n",
      "[5705]\n",
      "[5723]\n",
      "[5727]\n",
      "[5732]\n",
      "[5786]\n",
      "[5809]\n",
      "[5834]\n",
      "[5846]\n",
      "[5854]\n",
      "[5870]\n",
      "[5891]\n",
      "[5921]\n",
      "[5938]\n",
      "[5950]\n",
      "[5953]\n",
      "[5976]\n",
      "[6005]\n",
      "[6010]\n",
      "[6063]\n",
      "[6120]\n",
      "[6125]\n",
      "[6135]\n",
      "[6153]\n",
      "[6169]\n",
      "[6215]\n",
      "[6265]\n",
      "[6302]\n",
      "[6312]\n",
      "[6321]\n",
      "[6343]\n",
      "[6385]\n",
      "[6399]\n",
      "[6405]\n",
      "[6422]\n",
      "[6431]\n",
      "[6446]\n",
      "[6451]\n",
      "[6457]\n",
      "[6469]\n",
      "[6494]\n",
      "[6509]\n",
      "[6520]\n",
      "[6539]\n",
      "[6566]\n",
      "[6582]\n",
      "[6604]\n",
      "[6639]\n",
      "[6667]\n",
      "[6673]\n",
      "[6686]\n",
      "[6752]\n",
      "[6784]\n",
      "[6792]\n",
      "[6807]\n",
      "[6818]\n",
      "[6829]\n",
      "[6875]\n",
      "[6882]\n",
      "[6896]\n",
      "[6938]\n",
      "[6964]\n",
      "[6998]\n",
      "[7049]\n",
      "[7112]\n",
      "[7120]\n",
      "[7152]\n",
      "[7198]\n",
      "[7203]\n",
      "[7214]\n",
      "[7223]\n",
      "[7229]\n",
      "[7317]\n",
      "[7343]\n",
      "[7361]\n",
      "[7372]\n",
      "[7374]\n",
      "[7382]\n",
      "[7396]\n",
      "[7442]\n",
      "[7444]\n",
      "[7448]\n",
      "[7472]\n",
      "[7480]\n",
      "[7492]\n",
      "[7511]\n",
      "[7530]\n",
      "[7590]\n",
      "[7618]\n",
      "[7621]\n",
      "[7637]\n",
      "[7651]\n",
      "[7665]\n",
      "[7736]\n",
      "[7748]\n",
      "[7751]\n",
      "[7752]\n",
      "[7762]\n",
      "[7799]\n",
      "[7802]\n",
      "[7831]\n",
      "[7844]\n",
      "[7846]\n",
      "[7862]\n",
      "[7888]\n",
      "[7898]\n",
      "[7903]\n",
      "[7922]\n",
      "[7934]\n",
      "[7946]\n",
      "[7960]\n",
      "[7975]\n",
      "[7983]\n",
      "[7987]\n",
      "[7999]\n",
      "[8003]\n",
      "[8049]\n",
      "[8090]\n",
      "[8114]\n",
      "[8147]\n",
      "[8167]\n",
      "[8175]\n",
      "[8227]\n",
      "[8273]\n",
      "[8283]\n",
      "[8290]\n",
      "[8352]\n",
      "[8354]\n",
      "[8356]\n",
      "[8368]\n",
      "[8381]\n",
      "[8384]\n",
      "[8487]\n",
      "[8549]\n",
      "[8551]\n",
      "[8572]\n",
      "[8585]\n",
      "[8601]\n",
      "[8627]\n",
      "[8696]\n",
      "[8700]\n",
      "[8716]\n",
      "[8812]\n",
      "[8817]\n",
      "[8822]\n",
      "[8951]\n",
      "[8966]\n",
      "[8992]\n",
      "[9005]\n",
      "[9011]\n",
      "[9019]\n",
      "[9025]\n",
      "[9066]\n",
      "[9071]\n",
      "[9072]\n",
      "[9092]\n",
      "[9097]\n",
      "[9122]\n",
      "[9148]\n",
      "[9165]\n",
      "[9183]\n",
      "[9236]\n",
      "[9243]\n",
      "[9260]\n",
      "[9305]\n",
      "[9313]\n",
      "[9332]\n",
      "[9351]\n",
      "[9363]\n",
      "[9398]\n",
      "[9423]\n",
      "[9469]\n",
      "[9515]\n",
      "[9536]\n",
      "[9561]\n",
      "[9582]\n",
      "[9617]\n",
      "[9642]\n",
      "[9659]\n",
      "[9694]\n",
      "[9703]\n",
      "[9708]\n",
      "[9743]\n",
      "[9744]\n",
      "[9805]\n",
      "[9828]\n",
      "[9838]\n",
      "[9839]\n",
      "[9850]\n",
      "[9922]\n",
      "[9926]\n",
      "[9980]\n",
      "[9993]\n",
      "[10050]\n",
      "[10097]\n",
      "[10116]\n",
      "[10137]\n",
      "[10148]\n",
      "[10237]\n",
      "[10303]\n",
      "[10312]\n",
      "[10354]\n",
      "[10370]\n",
      "[10385]\n",
      "[10412]\n",
      "[10415]\n",
      "[10431]\n",
      "[10476]\n",
      "[10483]\n",
      "[10516]\n",
      "[10519]\n",
      "[10524]\n",
      "[10612]\n",
      "[10615]\n",
      "[10651]\n",
      "[10666]\n",
      "[10676]\n",
      "[10678]\n",
      "[10708]\n",
      "[10712]\n",
      "[10724]\n",
      "[10742]\n",
      "[10747]\n",
      "[10780]\n",
      "[10782]\n",
      "[10783]\n",
      "[10800]\n",
      "[10824]\n",
      "[10854]\n",
      "[10856]\n",
      "[10861]\n",
      "[10980]\n",
      "[11007]\n",
      "[11008]\n",
      "[11009]\n",
      "[11031]\n",
      "[11069]\n",
      "[11119]\n",
      "[11124]\n",
      "[11134]\n",
      "[11150]\n",
      "[11171]\n",
      "[11227]\n",
      "[11229]\n",
      "[11230]\n",
      "[11255]\n",
      "[11301]\n",
      "[11302]\n",
      "[11319]\n",
      "[11327]\n",
      "[11383]\n",
      "[11440]\n",
      "[11457]\n",
      "[11509]\n",
      "[11517]\n",
      "[11576]\n",
      "[11584]\n",
      "[11601]\n",
      "[11646]\n",
      "[11702]\n",
      "[11737]\n",
      "[11752]\n",
      "[11755]\n",
      "[11760]\n",
      "[11770]\n",
      "[11784]\n",
      "[11812]\n",
      "[11839]\n",
      "[11841]\n",
      "[11844]\n",
      "[11847]\n",
      "[11882]\n",
      "[11892]\n",
      "[11897]\n",
      "[11911]\n",
      "[11925]\n",
      "[11942]\n",
      "[11976]\n",
      "[11986]\n",
      "[11990]\n",
      "[12012]\n",
      "[12019]\n",
      "[12079]\n",
      "[12090]\n",
      "[12130]\n",
      "[12158]\n",
      "[12174]\n",
      "[12179]\n",
      "[12185]\n",
      "[12220]\n",
      "[12251]\n",
      "[12288]\n",
      "[12307]\n",
      "[12356]\n",
      "[12410]\n",
      "[12415]\n",
      "[12418]\n",
      "[12428]\n",
      "[12441]\n",
      "[12445]\n",
      "[12495]\n",
      "[12524]\n",
      "[12534]\n",
      "[12579]\n",
      "[12606]\n",
      "[12621]\n",
      "[12672]\n",
      "[12675]\n",
      "[12717]\n",
      "[12733]\n",
      "[12740]\n",
      "[12771]\n",
      "[12807]\n",
      "[12813]\n",
      "[12841]\n",
      "[12863]\n",
      "[12864]\n",
      "[12939]\n",
      "[12941]\n",
      "[13017]\n",
      "[13065]\n",
      "[13073]\n",
      "[13075]\n",
      "[13174]\n",
      "[13180]\n",
      "[13194]\n",
      "[13232]\n",
      "[13235]\n",
      "[13244]\n",
      "[13251]\n",
      "[13379]\n",
      "[13437]\n",
      "[13466]\n",
      "[13468]\n",
      "[13527]\n",
      "[13549]\n",
      "[13564]\n",
      "[13576]\n",
      "[13592]\n",
      "[13598]\n",
      "[13623]\n",
      "[13632]\n",
      "[13678]\n",
      "[13719]\n",
      "[13795]\n",
      "[13802]\n",
      "[13821]\n",
      "[13859]\n",
      "[13860]\n",
      "[13876]\n",
      "[13906]\n",
      "[13938]\n",
      "[13945]\n",
      "[13961]\n",
      "[13968]\n",
      "[14003]\n",
      "[14006]\n",
      "[14048]\n",
      "[14057]\n",
      "[14058]\n",
      "[14062]\n",
      "[14084]\n",
      "[14135]\n",
      "[14184]\n",
      "[14185]\n",
      "[14276]\n",
      "[14286]\n",
      "[14369]\n",
      "[14380]\n",
      "[14385]\n",
      "[14405]\n",
      "[14444]\n",
      "[14474]\n",
      "[14570]\n",
      "[14582]\n",
      "[14632]\n",
      "[14633]\n",
      "[14675]\n",
      "[14694]\n",
      "[14697]\n",
      "[14705]\n",
      "[14737]\n",
      "[14745]\n",
      "[14756]\n",
      "[14757]\n",
      "[14796]\n",
      "[14807]\n",
      "[14815]\n",
      "[14818]\n",
      "[14819]\n",
      "[14822]\n",
      "[14874]\n",
      "[14917]\n",
      "[14949]\n",
      "[14950]\n",
      "[14951]\n",
      "[14989]\n",
      "[14994]\n",
      "[15007]\n",
      "[15011]\n",
      "[15019]\n",
      "[15045]\n",
      "[15072]\n",
      "[15100]\n",
      "[15177]\n",
      "[15191]\n",
      "[15222]\n",
      "[15278]\n",
      "[15283]\n",
      "[15301]\n",
      "[15307]\n",
      "[15313]\n",
      "[15322]\n",
      "[15336]\n",
      "[15381]\n",
      "[15383]\n",
      "[15396]\n",
      "[15437]\n",
      "[15438]\n",
      "[15463]\n",
      "[15510]\n",
      "[15537]\n",
      "[15555]\n",
      "[15560]\n",
      "[15625]\n",
      "[15689]\n",
      "[15709]\n",
      "[15785]\n",
      "[15815]\n",
      "[15823]\n",
      "[15833]\n",
      "[15839]\n",
      "[15898]\n",
      "[15901]\n",
      "[15917]\n",
      "[15925]\n",
      "[15939]\n",
      "[15968]\n",
      "[15974]\n",
      "[16007]\n",
      "[16030]\n",
      "[16040]\n",
      "[16041]\n",
      "[16069]\n",
      "[16122]\n",
      "[16140]\n",
      "[16141]\n",
      "[16178]\n",
      "[16182]\n",
      "[16229]\n",
      "[16235]\n",
      "[16274]\n",
      "[16280]\n",
      "[16298]\n",
      "[16352]\n",
      "[16367]\n",
      "[16401]\n",
      "[16427]\n",
      "[16457]\n",
      "[16484]\n",
      "[16504]\n",
      "[16505]\n",
      "[16516]\n",
      "[16558]\n",
      "[16570]\n",
      "[16610]\n",
      "[16613]\n",
      "[16648]\n",
      "[16651]\n",
      "[16659]\n",
      "[16666]\n",
      "[16681]\n",
      "[16721]\n",
      "[16730]\n",
      "[16751]\n",
      "[16799]\n",
      "[16837]\n",
      "[16847]\n",
      "[16872]\n",
      "[16928]\n",
      "[16939]\n",
      "[16953]\n",
      "[16954]\n",
      "[16955]\n",
      "[16958]\n",
      "[16967]\n",
      "[16990]\n",
      "[17042]\n",
      "[17057]\n",
      "[17059]\n",
      "[17148]\n",
      "[17159]\n",
      "[17170]\n",
      "[17186]\n",
      "[17313]\n",
      "[17364]\n",
      "[17406]\n",
      "[17408]\n",
      "[17414]\n",
      "[17441]\n",
      "[17474]\n",
      "[17534]\n",
      "[17538]\n",
      "[17550]\n",
      "[17554]\n",
      "[17572]\n",
      "[17580]\n",
      "[17602]\n",
      "[17644]\n",
      "[17706]\n",
      "[17730]\n",
      "[17731]\n",
      "[17773]\n",
      "[17821]\n",
      "[17842]\n",
      "[17846]\n",
      "[17852]\n",
      "[17878]\n",
      "[17880]\n",
      "[17899]\n",
      "[17919]\n",
      "[17934]\n",
      "[17952]\n",
      "[18014]\n",
      "[18054]\n",
      "[18058]\n",
      "[18131]\n",
      "[18164]\n",
      "[18189]\n",
      "[18207]\n",
      "[18260]\n",
      "[18311]\n",
      "[18318]\n",
      "[18334]\n",
      "[18355]\n",
      "[18368]\n",
      "[18390]\n",
      "[18435]\n",
      "[18460]\n",
      "[18480]\n",
      "[18486]\n",
      "[18489]\n",
      "[18499]\n",
      "[18518]\n",
      "[18596]\n",
      "[18598]\n",
      "[18602]\n",
      "[18604]\n",
      "[18618]\n",
      "[18639]\n",
      "[18645]\n",
      "[18707]\n",
      "[18728]\n",
      "[18745]\n",
      "[18750]\n",
      "[18768]\n",
      "[18771]\n",
      "[18778]\n",
      "[18782]\n",
      "[18795]\n",
      "[18810]\n",
      "[18812]\n",
      "[18820]\n",
      "[18827]\n",
      "[18829]\n",
      "[18830]\n",
      "[18845]\n",
      "[18847]\n",
      "[18851]\n",
      "[18919]\n",
      "[18930]\n",
      "[18936]\n",
      "[18947]\n",
      "[18962]\n",
      "[18994]\n",
      "[19038]\n",
      "[19047]\n",
      "[19049]\n",
      "[19064]\n",
      "[19085]\n",
      "[19086]\n",
      "[19095]\n",
      "[19113]\n",
      "[19182]\n",
      "[19186]\n",
      "[19219]\n",
      "[19240]\n",
      "[19246]\n",
      "[19270]\n",
      "[19272]\n",
      "[19281]\n",
      "[19308]\n",
      "[19376]\n",
      "[19386]\n",
      "[19431]\n",
      "[19497]\n",
      "[19530]\n",
      "[19572]\n",
      "[19584]\n",
      "[19618]\n",
      "[19686]\n",
      "[19736]\n",
      "[19757]\n",
      "[19758]\n",
      "[19777]\n",
      "[19792]\n",
      "[19800]\n",
      "[19829]\n",
      "[19830]\n",
      "[19832]\n",
      "[19931]\n",
      "[19934]\n",
      "[19959]\n",
      "[19977]\n",
      "[20015]\n",
      "[20080]\n",
      "[20090]\n",
      "[20140]\n",
      "[20148]\n",
      "[20153]\n",
      "[20168]\n",
      "[20181]\n",
      "[20199]\n",
      "[20206]\n",
      "[20264]\n",
      "[20278]\n",
      "[20294]\n",
      "[20320]\n",
      "[20342]\n",
      "[20344]\n",
      "[20389]\n",
      "[20400]\n",
      "[20404]\n",
      "[20407]\n",
      "[20426]\n",
      "[20430]\n",
      "[20437]\n",
      "[20438]\n",
      "[20442]\n",
      "[20444]\n",
      "[20450]\n",
      "[20475]\n",
      "[20480]\n",
      "[20526]\n",
      "[20542]\n",
      "[20554]\n",
      "[20576]\n",
      "[20604]\n",
      "[20662]\n",
      "[20703]\n",
      "[20723]\n",
      "[20724]\n",
      "[20729]\n",
      "[20739]\n",
      "[20756]\n",
      "[20786]\n",
      "[20789]\n",
      "[20800]\n",
      "[20808]\n",
      "[20809]\n",
      "[20810]\n",
      "[20812]\n",
      "[20845]\n",
      "[20884]\n",
      "[20913]\n",
      "[20995]\n",
      "[21004]\n",
      "[21007]\n",
      "[21026]\n",
      "[21042]\n",
      "[21043]\n",
      "[21124]\n",
      "[21135]\n",
      "[21159]\n",
      "[21169]\n",
      "[21210]\n",
      "[21259]\n",
      "[21289]\n",
      "[21310]\n",
      "[21355]\n",
      "[21356]\n",
      "[21367]\n",
      "[21427]\n",
      "[21455]\n",
      "[21468]\n",
      "[21504]\n",
      "[21568]\n",
      "[21573]\n",
      "[21615]\n",
      "[21616]\n",
      "[21630]\n",
      "[21642]\n",
      "[21654]\n",
      "[21689]\n",
      "[21690]\n",
      "[21702]\n",
      "[21703]\n",
      "[21715]\n",
      "[21720]\n",
      "[21730]\n",
      "[21812]\n",
      "[21821]\n",
      "[21840]\n",
      "[21856]\n",
      "[21913]\n",
      "[21925]\n",
      "[21935]\n",
      "[21951]\n",
      "[21954]\n",
      "[21978]\n",
      "[21982]\n",
      "[21987]\n",
      "[22040]\n",
      "[22048]\n",
      "[22054]\n",
      "[22116]\n",
      "[22152]\n",
      "[22169]\n",
      "[22180]\n",
      "[22197]\n",
      "[22201]\n",
      "[22212]\n",
      "[22262]\n",
      "[22307]\n",
      "[22317]\n",
      "[22322]\n",
      "[22331]\n",
      "[22390]\n",
      "[22392]\n",
      "[22401]\n",
      "[22403]\n",
      "[22463]\n",
      "[22479]\n",
      "[22481]\n",
      "[22510]\n",
      "[22531]\n",
      "[22535]\n",
      "[22562]\n",
      "[22568]\n",
      "[22569]\n",
      "[22575]\n",
      "[22603]\n",
      "[22607]\n",
      "[22609]\n",
      "[22619]\n",
      "[22635]\n",
      "[22636]\n",
      "[22647]\n",
      "[22664]\n",
      "[22670]\n",
      "[22674]\n",
      "[22682]\n",
      "[22712]\n",
      "[22724]\n",
      "[22726]\n",
      "[22729]\n",
      "[22743]\n",
      "[22745]\n",
      "[22791]\n",
      "[22821]\n",
      "[22826]\n",
      "[22888]\n",
      "[22910]\n",
      "[22931]\n",
      "[22986]\n",
      "[23004]\n",
      "[23026]\n",
      "[23028]\n",
      "[23033]\n",
      "[23070]\n",
      "[23072]\n",
      "[23103]\n",
      "[23133]\n",
      "[23150]\n",
      "[23184]\n",
      "[23264]\n",
      "[23270]\n",
      "[23286]\n",
      "[23289]\n",
      "[23309]\n",
      "[23320]\n",
      "[23367]\n",
      "[23376]\n",
      "[23398]\n",
      "[23415]\n",
      "[23441]\n",
      "[23457]\n",
      "[23468]\n",
      "[23476]\n",
      "[23506]\n",
      "[23509]\n",
      "[23615]\n",
      "[23625]\n",
      "[23642]\n",
      "[23644]\n",
      "[23649]\n",
      "[23656]\n",
      "[23679]\n",
      "[23695]\n",
      "[23728]\n",
      "[23816]\n",
      "[23826]\n",
      "[23846]\n",
      "[23852]\n",
      "[23858]\n",
      "[23933]\n",
      "[24029]\n",
      "[24040]\n",
      "[24054]\n",
      "[24061]\n",
      "[24067]\n",
      "[24091]\n",
      "[24114]\n",
      "[24142]\n",
      "[24200]\n",
      "[24207]\n",
      "[24242]\n",
      "[24245]\n",
      "[24307]\n",
      "[24331]\n",
      "[24338]\n",
      "[24377]\n",
      "[24380]\n",
      "[24437]\n",
      "[24438]\n",
      "[24454]\n",
      "[24475]\n",
      "[24476]\n",
      "[24489]\n",
      "[24539]\n",
      "[24540]\n",
      "[24541]\n",
      "[24588]\n",
      "[24635]\n",
      "[24731]\n",
      "[24735]\n",
      "[24741]\n",
      "[24745]\n",
      "[24763]\n",
      "[24796]\n",
      "[24810]\n",
      "[24821]\n",
      "[24824]\n",
      "[24829]\n",
      "[24832]\n",
      "[24866]\n",
      "[24869]\n",
      "[24895]\n",
      "[24900]\n",
      "[24928]\n",
      "[24948]\n",
      "[24951]\n",
      "[24959]\n",
      "[24985]\n",
      "[25002]\n",
      "[25006]\n",
      "[25009]\n",
      "[25042]\n",
      "[25074]\n",
      "[25086]\n",
      "[25104]\n",
      "[25105]\n",
      "[25112]\n",
      "[25146]\n",
      "[25172]\n",
      "[25260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25318]\n",
      "[25389]\n",
      "[25406]\n",
      "[25440]\n",
      "[25457]\n",
      "[25465]\n",
      "[25480]\n",
      "[25506]\n",
      "[25543]\n",
      "[25547]\n",
      "[25624]\n",
      "[25632]\n",
      "[25692]\n",
      "[25696]\n",
      "[25699]\n",
      "[25707]\n",
      "[25727]\n",
      "[25743]\n",
      "[25752]\n",
      "[25753]\n",
      "[25769]\n",
      "[25772]\n",
      "[25815]\n",
      "[25816]\n",
      "[25824]\n",
      "[25840]\n",
      "[25863]\n",
      "[25872]\n",
      "[25913]\n",
      "[25952]\n",
      "[26019]\n",
      "[26027]\n",
      "[26030]\n",
      "[26035]\n",
      "[26088]\n",
      "[26098]\n",
      "[26133]\n",
      "[26140]\n",
      "[26176]\n",
      "[26238]\n",
      "[26247]\n",
      "[26264]\n",
      "[26304]\n",
      "[26343]\n",
      "[26364]\n",
      "[26367]\n",
      "[26449]\n",
      "[26477]\n",
      "[26505]\n",
      "[26532]\n",
      "[26541]\n",
      "[26544]\n",
      "[26548]\n",
      "[26561]\n",
      "[26581]\n",
      "[26613]\n",
      "[26659]\n",
      "[26660]\n",
      "[26663]\n",
      "[26686]\n",
      "[26707]\n",
      "[26719]\n",
      "[26791]\n",
      "[26807]\n",
      "[26827]\n",
      "[26859]\n",
      "[26902]\n",
      "[26930]\n",
      "[26970]\n",
      "[26999]\n",
      "[27025]\n",
      "[27045]\n",
      "[27075]\n",
      "[27100]\n",
      "[27108]\n",
      "[27142]\n",
      "[27149]\n",
      "[27162]\n",
      "[27164]\n",
      "[27177]\n",
      "[27180]\n",
      "[27213]\n",
      "[27249]\n",
      "[27253]\n",
      "[27290]\n",
      "[27365]\n",
      "[27382]\n",
      "[27462]\n",
      "[27481]\n",
      "[27538]\n",
      "[27547]\n",
      "[27550]\n",
      "[27573]\n",
      "[27580]\n",
      "[27615]\n",
      "[27645]\n",
      "[27650]\n",
      "[27659]\n",
      "[27662]\n",
      "[27702]\n",
      "[27713]\n",
      "[27716]\n",
      "[27734]\n",
      "[27749]\n",
      "[27772]\n",
      "[27787]\n",
      "[27793]\n",
      "[27799]\n",
      "[27826]\n",
      "[27830]\n",
      "[27832]\n",
      "[27853]\n",
      "[27874]\n",
      "[27876]\n",
      "[27884]\n",
      "[27894]\n",
      "[27904]\n",
      "[27915]\n",
      "[27941]\n",
      "[27946]\n",
      "[27961]\n",
      "[27982]\n",
      "[28053]\n",
      "[28059]\n",
      "[28095]\n",
      "[28113]\n",
      "[28130]\n",
      "[28167]\n",
      "[28170]\n",
      "[28226]\n",
      "[28229]\n",
      "[28231]\n",
      "[28340]\n",
      "[28375]\n",
      "[28383]\n",
      "[28394]\n",
      "[28470]\n",
      "[28482]\n",
      "[28515]\n",
      "[28530]\n",
      "[28544]\n",
      "[28580]\n",
      "[28589]\n",
      "[28595]\n",
      "[28691]\n",
      "[28693]\n",
      "[28697]\n",
      "[28715]\n",
      "[28719]\n",
      "[28723]\n",
      "[28725]\n",
      "[28774]\n",
      "[28853]\n",
      "[28887]\n",
      "[28894]\n",
      "[28903]\n",
      "[28908]\n",
      "[28911]\n",
      "[28913]\n",
      "[28953]\n",
      "[28963]\n",
      "[28974]\n",
      "[28995]\n",
      "[29019]\n",
      "[29049]\n",
      "[29052]\n",
      "[29112]\n",
      "[29133]\n",
      "[29138]\n",
      "[29150]\n",
      "[29185]\n",
      "[29220]\n",
      "[29227]\n",
      "[29254]\n",
      "[29290]\n",
      "[29298]\n",
      "[29350]\n",
      "[29404]\n",
      "[29429]\n",
      "[29442]\n",
      "[29444]\n",
      "[29450]\n",
      "[29466]\n",
      "[29475]\n",
      "[29499]\n",
      "[29538]\n",
      "[29571]\n",
      "[29591]\n",
      "[29596]\n",
      "[29615]\n",
      "[29623]\n",
      "[29635]\n",
      "[29707]\n",
      "[29711]\n",
      "[29714]\n",
      "[29733]\n",
      "[29736]\n",
      "[29739]\n",
      "[29743]\n",
      "[29744]\n",
      "[29751]\n",
      "[29756]\n",
      "[29766]\n",
      "[29777]\n",
      "[29786]\n",
      "[29810]\n",
      "[29836]\n",
      "[29850]\n",
      "[29864]\n",
      "[29889]\n",
      "[29912]\n",
      "[29926]\n",
      "[29929]\n",
      "[29936]\n",
      "[29949]\n",
      "[29959]\n",
      "[29969]\n",
      "[29979]\n",
      "[29981]\n",
      "[30011]\n",
      "[30057]\n",
      "[30086]\n",
      "[30102]\n",
      "[30122]\n",
      "[30144]\n",
      "[30173]\n",
      "[30185]\n",
      "[30186]\n",
      "[30206]\n",
      "[30213]\n",
      "[30254]\n",
      "[30263]\n",
      "[30267]\n",
      "[30288]\n",
      "[30292]\n",
      "[30327]\n",
      "[30336]\n",
      "[30348]\n",
      "[30439]\n",
      "[30440]\n",
      "[30444]\n",
      "[30445]\n",
      "[30476]\n",
      "[30490]\n",
      "[30523]\n",
      "[30611]\n",
      "[30613]\n",
      "[30656]\n",
      "[30683]\n",
      "[30708]\n",
      "[30741]\n",
      "[30742]\n",
      "[30747]\n",
      "[30753]\n",
      "[30758]\n",
      "[30760]\n",
      "[30774]\n",
      "[30808]\n",
      "[30829]\n",
      "[30830]\n",
      "[30864]\n",
      "[30865]\n",
      "[30877]\n",
      "[30886]\n",
      "[30902]\n",
      "[30904]\n",
      "[30908]\n",
      "[30913]\n",
      "[30924]\n",
      "[30926]\n",
      "[30933]\n",
      "[30972]\n",
      "[30999]\n",
      "[31037]\n",
      "[31083]\n",
      "[31095]\n",
      "[31099]\n",
      "[31101]\n",
      "[31115]\n",
      "[31125]\n",
      "[31193]\n",
      "[31247]\n",
      "[31249]\n",
      "[31251]\n",
      "[31256]\n",
      "[31285]\n",
      "[31292]\n",
      "[31296]\n",
      "[31308]\n",
      "[31367]\n",
      "[31390]\n",
      "[31418]\n",
      "[31421]\n",
      "[31483]\n",
      "[31542]\n",
      "[31564]\n",
      "[31631]\n",
      "[31638]\n",
      "[31650]\n",
      "[31668]\n",
      "[31669]\n",
      "[31712]\n",
      "[31721]\n",
      "[31775]\n",
      "[31822]\n",
      "[31846]\n",
      "[31875]\n",
      "[31890]\n",
      "[31943]\n",
      "[32006]\n",
      "[32026]\n",
      "[32042]\n",
      "[32052]\n",
      "[32064]\n",
      "[32080]\n",
      "[32098]\n",
      "[32147]\n",
      "[32246]\n",
      "[32250]\n",
      "[32263]\n",
      "[32279]\n",
      "[32328]\n",
      "[32331]\n",
      "[32363]\n",
      "[32370]\n",
      "[32392]\n",
      "[32417]\n",
      "[32479]\n",
      "[32496]\n",
      "[32504]\n",
      "[32569]\n",
      "[32576]\n",
      "[32596]\n",
      "[32607]\n",
      "[32616]\n",
      "[32683]\n",
      "[32689]\n",
      "[32693]\n",
      "[32728]\n",
      "[32743]\n",
      "[32749]\n",
      "[32768]\n",
      "[32774]\n",
      "[32801]\n",
      "[32807]\n",
      "[32867]\n",
      "[32871]\n",
      "[32891]\n",
      "[32898]\n",
      "[32904]\n",
      "[32933]\n",
      "[32954]\n",
      "[32974]\n",
      "[32983]\n",
      "[33010]\n",
      "[33016]\n",
      "[33024]\n",
      "[33046]\n",
      "[33111]\n",
      "[33121]\n",
      "[33137]\n",
      "[33168]\n",
      "[33183]\n",
      "[33207]\n",
      "[33235]\n",
      "[33256]\n",
      "[33263]\n",
      "[33280]\n",
      "[33291]\n",
      "[33326]\n",
      "[33380]\n",
      "[33423]\n",
      "[33437]\n",
      "[33438]\n",
      "[33444]\n",
      "[33452]\n",
      "[33479]\n",
      "[33480]\n",
      "[33491]\n",
      "[33512]\n",
      "[33571]\n",
      "[33590]\n",
      "[33599]\n",
      "[33643]\n",
      "[33649]\n",
      "[33665]\n",
      "[33710]\n",
      "[33756]\n",
      "[33771]\n",
      "[33795]\n",
      "[33830]\n",
      "[33843]\n",
      "[33921]\n",
      "[33924]\n",
      "[33939]\n",
      "[33953]\n",
      "[33968]\n",
      "[33970]\n",
      "[33989]\n",
      "[33992]\n",
      "[34036]\n",
      "[34098]\n",
      "[34134]\n",
      "[34218]\n",
      "[34255]\n",
      "[34282]\n",
      "[34295]\n",
      "[34329]\n",
      "[34348]\n",
      "[34380]\n",
      "[34394]\n",
      "[34400]\n",
      "[34408]\n",
      "[34436]\n",
      "[34438]\n",
      "[34467]\n",
      "[34477]\n",
      "[34535]\n",
      "[34552]\n",
      "[34554]\n",
      "[34557]\n",
      "[34601]\n",
      "[34638]\n",
      "[34658]\n",
      "[34676]\n",
      "[34677]\n",
      "[34681]\n",
      "[34693]\n",
      "[34706]\n",
      "[34709]\n",
      "[34718]\n",
      "[34746]\n",
      "[34775]\n",
      "[34781]\n",
      "[34856]\n",
      "[34858]\n",
      "[34871]\n",
      "[34894]\n",
      "[34896]\n",
      "[34920]\n",
      "[34927]\n",
      "[34932]\n",
      "[34949]\n",
      "[34991]\n",
      "[35009]\n",
      "[35023]\n",
      "[35069]\n",
      "[35084]\n",
      "[35095]\n",
      "[35105]\n",
      "[35111]\n",
      "[35117]\n",
      "[35135]\n",
      "[35144]\n",
      "[35175]\n",
      "[35209]\n",
      "[35259]\n",
      "[35262]\n",
      "[35305]\n",
      "[35311]\n",
      "[35312]\n",
      "[35319]\n",
      "[35324]\n",
      "[35353]\n",
      "[35358]\n",
      "[35372]\n",
      "[35423]\n",
      "[35480]\n",
      "[35524]\n",
      "[35534]\n",
      "[35607]\n",
      "[35615]\n",
      "[35628]\n",
      "[35632]\n",
      "[35675]\n",
      "[35700]\n",
      "[35717]\n",
      "[35758]\n"
     ]
    }
   ],
   "source": [
    "print(len(matrix_df1[:,0]))\n",
    "print(np.sort(matrix_df[:, -1]))\n",
    "\n",
    "master_mat1 = np.zeros((4000, 12))\n",
    "\n",
    "for i in range(4000):\n",
    "    if matrix_df[i,-1] in master_mat[:, 0]:\n",
    "        ind = np.where(master_mat[:, 0] == matrix_df[i,-1])[0]\n",
    "        print(ind)\n",
    "        master_mat1[i,:] = master_mat[ind,:]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "master_mat1 = master_mat1[~np.all(master_mat1 == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole1 = np.zeros((np.shape(master_mat1)[0], 170))\n",
    "\n",
    "for i in range(np.shape(master_mat1)[0]):\n",
    "    if matrix_df[i,-1] in master_mat1[:, 0]:\n",
    "        whole1[i, :] = matrix_df[i, :]\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    2201        0        0        0        0        0        0        0\n",
      "        0        0        0        0        0        0        0        0\n",
      "        0        0        2        3        0        0        0        0\n",
      "        0        0        0        0        0        0        0        0\n",
      "        0        0        0        0        0        0        0        9\n",
      "        7        6        4       10        8        5       10       17\n",
      "        2        4        1        0        3        3        0        0\n",
      "        4        0        0        0        0        0        0        4\n",
      "        9       11        5        0       11        7        9        9\n",
      "        6        5        0        0        1        0        0        0\n",
      "        0        0        0        0        0        0        0        5\n",
      "        9        2        2        7        3        3        6       10\n",
      "        5        0        0        0        0        0        0        0\n",
      "        0        0        0        0        0        8        4        4\n",
      "       14        8       11        4        7       17        3       11\n",
      "        5        2        3        0        0        2        0        0\n",
      "        0        0        0        0        0        0        1        4\n",
      "        6        0        3        3        2        1        4        5\n",
      "        0        0        0        0        0        0        0        0\n",
      "        0        0        0        0        0        0        3        1\n",
      "        2        3        0        2        0        0        0        0\n",
      "        0 81253085]\n"
     ]
    }
   ],
   "source": [
    "print(matrix_df[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22850883e+08 1.39267316e+08 1.49318045e+08 1.53365641e+08\n",
      " 1.62945400e+08 1.63379979e+08 1.64054373e+08 1.64697257e+08\n",
      " 1.64699726e+08 1.64744235e+08]\n",
      "[1.39267316e+08 3.66600000e+01 9.90000000e+01 4.00000000e+00\n",
      " 1.00000000e+00 4.00000000e+00 1.10000000e+01 0.00000000e+00\n",
      " 5.00000000e+00 1.00000000e+00 0.00000000e+00 8.41180000e+04]\n",
      "[1.49318045e+08 6.69600000e+02 3.00000000e+00 3.00000000e+00\n",
      " 2.00000000e+00 4.00000000e+00 1.10000000e+01 0.00000000e+00\n",
      " 5.00000000e+00 1.00000000e+00 1.00000000e+00 3.28220000e+04]\n",
      "(1579, 12)\n",
      "(1579, 170)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1d1f5e0446ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mwhole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhole\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mwhole_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhole\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mencoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#encoded_imgs = np.reshape(encoded_imgs[:,:,:,1], (1579, 14))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "print(master_mat1[0:10,0])\n",
    "print(master_mat[22,:])\n",
    "print(master_mat1[2,:])\n",
    "\n",
    "print(np.shape(master_mat1))\n",
    "print(np.shape(whole1))\n",
    "\n",
    "whole = whole1[whole1[:, -1].argsort()]\n",
    "whole = whole[:,1:-1]\n",
    "whole_final = np.reshape(whole, (len(whole), 7, 24, 1))\n",
    "encoded_imgs = encoder.predict(whole)\n",
    "\n",
    "#encoded_imgs = np.reshape(encoded_imgs[:,:,:,1], (1579, 14))\n",
    "\n",
    "print(np.shape(whole_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22850883e+08 4.26995000e+03 5.00000000e+00 1.00000000e+00\n",
      " 5.00000000e+00 8.00000000e+00 1.60000000e+01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 0.00000000e+00 1.58100000e+03\n",
      " 6.28590405e-01 6.41867697e-01 0.00000000e+00 6.45653427e-01\n",
      " 1.25643981e+00 7.03237236e-01 6.40043318e-01 6.27059758e-01\n",
      " 6.46527767e-01 7.68492997e-01 6.32890642e-01 6.40724838e-01]\n",
      "[1.49318045e+08 6.69600000e+02 3.00000000e+00 3.00000000e+00\n",
      " 2.00000000e+00 4.00000000e+00 1.10000000e+01 0.00000000e+00\n",
      " 5.00000000e+00 1.00000000e+00 1.00000000e+00 3.28220000e+04\n",
      " 6.28590405e-01 6.41867697e-01 0.00000000e+00 6.45653427e-01\n",
      " 1.25643981e+00 7.03237236e-01 6.40043318e-01 6.27059758e-01\n",
      " 6.46527767e-01 7.68492997e-01 6.32890642e-01 6.40724838e-01]\n",
      "[1.65626370e+08 2.39000000e+01 2.00000000e+00 3.00000000e+00\n",
      " 5.00000000e+00 1.10000000e+01 1.10000000e+01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 0.00000000e+00 7.06610000e+04\n",
      " 6.28590405e-01 6.41867697e-01 0.00000000e+00 6.45653427e-01\n",
      " 1.25643981e+00 7.03237236e-01 6.40043318e-01 6.27059758e-01\n",
      " 6.46527767e-01 7.68492997e-01 6.32890642e-01 6.40724838e-01]\n"
     ]
    }
   ],
   "source": [
    "final_mat = np.concatenate((master_mat1, encoded_imgs), axis=1)\n",
    "print(final_mat[0,:])\n",
    "print(final_mat[2,:])\n",
    "print(final_mat[10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1579, 168)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "d = whole1[:, 1:-1]\n",
    "standardized_data = StandardScaler().fit_transform(d)\n",
    "print(standardized_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of co-variance matrix =  (168, 168)\n"
     ]
    }
   ],
   "source": [
    "# Once the data is standardized i.e, mean = 0, std.deviation = 1;\n",
    "# then the co-variance matrix of A is calculated as : A^T * A\n",
    "\n",
    "sample_data = standardized_data\n",
    "\n",
    "# matrix multiplication using numpy\n",
    "covar_matrix = np.matmul(sample_data.T , sample_data)\n",
    "\n",
    "print ( \"The shape of co-variance matrix = \", covar_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of eigen vectors =  (168, 2)\n",
      "Updated shape of eigen vectors =  (2, 168)\n"
     ]
    }
   ],
   "source": [
    "#finding the top two eigen-values and corresponding eigen-vectors \n",
    "# for projecting onto a 2-Dim space.\n",
    "\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "# the parameter 'eigvals' is defined (low value to high value) \n",
    "# eigh function will return the eigen values in asending order\n",
    "# this code generates only the top 2 (166 and 167) eigenvalues.\n",
    "\n",
    "values, vectors = eigh(covar_matrix, eigvals=(166,167))\n",
    "\n",
    "print(\"Shape of eigen vectors = \",vectors.shape)\n",
    "# converting the eigen vectors into (2,d) shape for easyness of further computations\n",
    "vectors = vectors.T\n",
    "\n",
    "print(\"Updated shape of eigen vectors = \",vectors.shape)\n",
    "# here the vectors[1] represent the eigen vector corresponding 1st principal eigen vector\n",
    "# here the vectors[0] represent the eigen vector corresponding 2nd principal eigen vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " resultanat new data points' shape  (2, 168) X (168, 1579)  =  (2, 1579)\n"
     ]
    }
   ],
   "source": [
    "# projecting the original data sample on the plane \n",
    "# formed by two principal eigen vectors by vector-vector multiplication.\n",
    "\n",
    "new_coordinates = np.matmul(vectors, sample_data.T)\n",
    "\n",
    "print (\" resultanat new data points' shape \", vectors.shape, \"X\", sample_data.T.shape,\" = \", new_coordinates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the pca\n",
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pca_reduced.shape =  (1579, 10)\n",
      "[[-3.62855974 -0.06854481  0.10469364 ...  0.04620442 -0.01187267\n",
      "   0.01566495]\n",
      " [ 3.16169373 -2.34987441 -1.27650968 ...  1.17776483 -0.22057947\n",
      "   0.95867229]\n",
      " [-3.62855974 -0.06854481  0.10469364 ...  0.04620442 -0.01187267\n",
      "   0.01566495]\n",
      " ...\n",
      " [11.13622175 -4.1607524  -6.92790277 ...  3.32577924 -1.25781461\n",
      "  -0.84508473]\n",
      " [ 8.655779    0.69292354 -4.25551859 ...  3.55371079  0.23577681\n",
      "  -2.39101091]\n",
      " [-3.62855974 -0.06854481  0.10469364 ...  0.04620442 -0.01187267\n",
      "   0.01566495]]\n"
     ]
    }
   ],
   "source": [
    "# configuring the parameteres\n",
    "# the number of components = 10\n",
    "pca.n_components = 10\n",
    "pca_data = pca.fit_transform(sample_data)\n",
    "\n",
    "# pca_reduced will contain the 2-d projects of simple data\n",
    "print(\"shape of pca_reduced.shape = \", pca_data.shape)\n",
    "print(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PCA for dimensionality reduction (non-visualization)\n",
    "\n",
    "pca.n_components = 10\n",
    "pca_data = pca.fit_transform(sample_data)\n",
    "\n",
    "percentage_var_explained = pca.explained_variance_ / np.sum(pca.explained_variance_);\n",
    "\n",
    "cum_var_explained = np.cumsum(percentage_var_explained)\n",
    "\n",
    "# Plot the PCA spectrum\n",
    "plt.figure(1, figsize=(6, 4))\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(cum_var_explained, linewidth=2)\n",
    "plt.axis('tight')\n",
    "plt.grid()\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('Cumulative_explained_variance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# If we take 200-dimensions, approx. 90% of variance is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mat = np.concatenate((master_mat1, pca_data), axis=1)\n",
    "#col 1: machine id\n",
    "#col 2: basket total price\n",
    "#col 3: highest lvl of education for hoh (99/3001/3002/3005 = unknown)\n",
    "#col 4: US geographic region (1 = NE, 2 = NC, 3 = S, 4 = W, 88/99 = unknown)\n",
    "#col 5: # of ppl in household (99 = unknown)\n",
    "#col 6: age of hoh (tiered)\n",
    "#col 7: combined household income (99 = unknown, 11 - 18 = 2014 to present)\n",
    "#col 8: whether there is a child in household (1 = yes)\n",
    "#col 9: race of hoh (1 = caucasian, 2 = african american, 3 = asian, 5 = other, -88/99 = other)\n",
    "#col 10: whether household has broadband (1 = yes)\n",
    "#col 11: hispanic self identification (1 = hispanic)\n",
    "#col 12: zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.22850883e+08  4.26995000e+03  5.00000000e+00  1.00000000e+00\n",
      "  5.00000000e+00  8.00000000e+00  1.60000000e+01  1.00000000e+00\n",
      "  1.00000000e+00  1.00000000e+00  0.00000000e+00  1.58100000e+03\n",
      " -3.62855974e+00 -6.85448114e-02  1.04693640e-01 -1.92716112e-02\n",
      "  7.50690260e-02  2.95484992e-03  8.08697594e-02  4.62044678e-02\n",
      " -1.18738388e-02  1.56603140e-02]\n"
     ]
    }
   ],
   "source": [
    "print(final_mat[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Machine_ID</th>\n",
       "      <th>Basket_Total_Price</th>\n",
       "      <th>household_size</th>\n",
       "      <th>age_of_hoh</th>\n",
       "      <th>household_income</th>\n",
       "      <th>children</th>\n",
       "      <th>broadband</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>...</th>\n",
       "      <th>Region_1.0</th>\n",
       "      <th>Region_2.0</th>\n",
       "      <th>Region_3.0</th>\n",
       "      <th>Region_4.0</th>\n",
       "      <th>highest_hoh_edu_1.0</th>\n",
       "      <th>highest_hoh_edu_2.0</th>\n",
       "      <th>highest_hoh_edu_3.0</th>\n",
       "      <th>highest_hoh_edu_4.0</th>\n",
       "      <th>highest_hoh_edu_5.0</th>\n",
       "      <th>highest_hoh_edu_99.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122850883.0</td>\n",
       "      <td>4269.95</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1581.0</td>\n",
       "      <td>-3.628560</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139267316.0</td>\n",
       "      <td>36.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84118.0</td>\n",
       "      <td>3.161694</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149318045.0</td>\n",
       "      <td>669.60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32822.0</td>\n",
       "      <td>-3.628560</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153365641.0</td>\n",
       "      <td>49732.68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62220.0</td>\n",
       "      <td>-3.628560</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162945400.0</td>\n",
       "      <td>86.72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75025.0</td>\n",
       "      <td>-3.628560</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Machine_ID  Basket_Total_Price  household_size  age_of_hoh  \\\n",
       "0  122850883.0             4269.95             5.0         8.0   \n",
       "1  139267316.0               36.66             1.0         4.0   \n",
       "2  149318045.0              669.60             2.0         4.0   \n",
       "3  153365641.0            49732.68             5.0        11.0   \n",
       "4  162945400.0               86.72             2.0         9.0   \n",
       "\n",
       "   household_income  children  broadband  hispanic  zipcode      PCA1  ...  \\\n",
       "0              16.0       1.0        1.0       0.0   1581.0 -3.628560  ...   \n",
       "1              11.0       0.0        1.0       0.0  84118.0  3.161694  ...   \n",
       "2              11.0       0.0        1.0       1.0  32822.0 -3.628560  ...   \n",
       "3              11.0       1.0        1.0       0.0  62220.0 -3.628560  ...   \n",
       "4              16.0       1.0        1.0       0.0  75025.0 -3.628560  ...   \n",
       "\n",
       "   Region_1.0  Region_2.0  Region_3.0  Region_4.0  highest_hoh_edu_1.0  \\\n",
       "0           1           0           0           0                    0   \n",
       "1           0           0           0           1                    0   \n",
       "2           0           0           1           0                    0   \n",
       "3           0           1           0           0                    0   \n",
       "4           0           0           1           0                    0   \n",
       "\n",
       "   highest_hoh_edu_2.0  highest_hoh_edu_3.0  highest_hoh_edu_4.0  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    1                    0   \n",
       "3                    1                    0                    0   \n",
       "4                    0                    1                    0   \n",
       "\n",
       "   highest_hoh_edu_5.0  highest_hoh_edu_99.0  \n",
       "0                    1                     0  \n",
       "1                    0                     1  \n",
       "2                    0                     0  \n",
       "3                    0                     0  \n",
       "4                    0                     0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn to pd to deal with factors\n",
    "final_df = pd.DataFrame(final_mat, columns = ['Machine_ID','Basket_Total_Price','highest_hoh_edu', 'Region', 'household_size','age_of_hoh', 'household_income', 'children', 'race_of_hoh', 'broadband', 'hispanic', 'zipcode', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10'])\n",
    "pd.get_dummies(final_df, columns=[\"race_of_hoh\", \"Region\", \"highest_hoh_edu\"]).head() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selected(data, response):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "    response: string, name of response column in data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" fitted statsmodels linear model\n",
    "           with an intercept\n",
    "           selected by forward selection\n",
    "           evaluated by adjusted R-squared\n",
    "    \"\"\"\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    while remaining and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, data).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if current_score < best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(selected))\n",
    "    model = smf.ols(formula, data).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ffa5f4e939ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Basket_Total_Price'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'highest_hoh_edu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Region'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'household_size'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'age_of_hoh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'household_income'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'children'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'race_of_hoh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'broadband'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hispanic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zipcode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PCA1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PCA2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PCA3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PCA4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PCA5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PCA6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PCA7'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PCA8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PCA9'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PCA10'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_selected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# amogos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "data = final_df[['Basket_Total_Price','highest_hoh_edu', 'Region', 'household_size','age_of_hoh', 'household_income', 'children', 'race_of_hoh', 'broadband', 'hispanic', 'zipcode', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10']]\n",
    "model = forward_selected(data, data.columns[0]) # amogos\n",
    "\n",
    "print(model.model.formula)\n",
    "\n",
    "mod = smf.ols(formula=model.model.formula, data=data)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     Basket_Total_Price   R-squared:                       0.012\n",
      "Model:                            OLS   Adj. R-squared:                 -0.003\n",
      "Method:                 Least Squares   F-statistic:                    0.8212\n",
      "Date:                Mon, 11 Apr 2022   Prob (F-statistic):              0.707\n",
      "Time:                        09:21:24   Log-Likelihood:                -16412.\n",
      "No. Observations:                1579   AIC:                         3.287e+04\n",
      "Df Residuals:                    1555   BIC:                         3.300e+04\n",
      "Df Model:                          23                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept             -1962.2904   3413.846     -0.575      0.566   -8658.517    4733.937\n",
      "C(Region)[T.2.0]        302.7954    641.495      0.472      0.637    -955.490    1561.081\n",
      "C(Region)[T.3.0]        -54.2373    557.547     -0.097      0.923   -1147.861    1039.386\n",
      "C(Region)[T.4.0]       -301.2019    638.418     -0.472      0.637   -1553.453     951.049\n",
      "C(race_of_hoh)[T.2.0]    43.1523    644.511      0.067      0.947   -1221.050    1307.355\n",
      "C(race_of_hoh)[T.3.0]   200.9400    834.769      0.241      0.810   -1436.451    1838.331\n",
      "C(race_of_hoh)[T.5.0]  1563.4339    653.116      2.394      0.017     282.353    2844.515\n",
      "highest_hoh_edu          -3.2586      6.071     -0.537      0.592     -15.167       8.650\n",
      "household_size          -25.2387     56.423     -0.447      0.655    -135.913      85.435\n",
      "age_of_hoh              162.9993     81.005      2.012      0.044       4.109     321.890\n",
      "household_income        105.0776     97.884      1.073      0.283     -86.921     297.076\n",
      "children                462.2351    430.214      1.074      0.283    -381.626    1306.096\n",
      "broadband               580.4701   3039.173      0.191      0.849   -5380.840    6541.780\n",
      "hispanic                738.1605    563.320      1.310      0.190    -366.787    1843.108\n",
      "PCA1                     -4.6490     23.133     -0.201      0.841     -50.024      40.726\n",
      "PCA2                     23.9799     44.209      0.542      0.588     -62.735     110.695\n",
      "PCA3                     -4.4834     51.793     -0.087      0.931    -106.074      97.107\n",
      "PCA4                     54.5862     56.106      0.973      0.331     -55.466     164.639\n",
      "PCA5                    -28.1333     79.466     -0.354      0.723    -184.005     127.738\n",
      "PCA6                     44.5108     89.255      0.499      0.618    -130.562     219.584\n",
      "PCA7                    -69.3188    105.832     -0.655      0.513    -276.907     138.269\n",
      "PCA8                    -36.6686    115.717     -0.317      0.751    -263.647     190.310\n",
      "PCA9                    -14.5574    132.264     -0.110      0.912    -273.991     244.876\n",
      "PCA10                    71.3518    147.722      0.483      0.629    -218.403     361.107\n",
      "==============================================================================\n",
      "Omnibus:                     4065.033   Durbin-Watson:                   2.017\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         60236505.526\n",
      "Skew:                          27.855   Prob(JB):                         0.00\n",
      "Kurtosis:                     958.228   Cond. No.                         873.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod_all = smf.ols(formula='Basket_Total_Price ~ highest_hoh_edu+C(Region)+household_size+age_of_hoh+household_income+children+C(race_of_hoh)+broadband+hispanic+PCA1+PCA2+PCA3+PCA4+PCA5+PCA6+PCA7+PCA8+PCA9+PCA10', data=data)\n",
    "res_all = mod_all.fit()\n",
    "print(res_all.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     Basket_Total_Price   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     3.369\n",
      "Date:                Mon, 11 Apr 2022   Prob (F-statistic):             0.0666\n",
      "Time:                        01:54:46   Log-Likelihood:                -16420.\n",
      "No. Observations:                1579   AIC:                         3.284e+04\n",
      "Df Residuals:                    1577   BIC:                         3.285e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    668.2874    625.384      1.069      0.285    -558.384    1894.959\n",
      "age_of_hoh   142.7748     77.782      1.836      0.067      -9.792     295.341\n",
      "==============================================================================\n",
      "Omnibus:                     4082.517   Durbin-Watson:                   2.017\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         61943355.513\n",
      "Skew:                          28.159   Prob(JB):                         0.00\n",
      "Kurtosis:                     971.677   Cond. No.                         25.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod2 = smf.ols(formula='Basket_Total_Price ~ age_of_hoh + 1', data=data)\n",
    "res2 = mod2.fit()\n",
    "print(res2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     Basket_Total_Price   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.001\n",
      "Method:                 Least Squares   F-statistic:                   0.02352\n",
      "Date:                Mon, 11 Apr 2022   Prob (F-statistic):              0.878\n",
      "Time:                        09:49:56   Log-Likelihood:                -16421.\n",
      "No. Observations:                1579   AIC:                         3.285e+04\n",
      "Df Residuals:                    1577   BIC:                         3.286e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept       1780.9879    258.273      6.896      0.000    1274.394    2287.582\n",
      "household_size    -8.3579     54.500     -0.153      0.878    -115.259      98.543\n",
      "==============================================================================\n",
      "Omnibus:                     4085.775   Durbin-Watson:                   2.021\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         62262258.585\n",
      "Skew:                          28.216   Prob(JB):                         0.00\n",
      "Kurtosis:                     974.169   Cond. No.                         6.23\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod3 = smf.ols(formula='Basket_Total_Price ~ household_size + 1', data=data)\n",
    "res3 = mod3.fit()\n",
    "print(res3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     Basket_Total_Price   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.001\n",
      "Method:                 Least Squares   F-statistic:                   0.04251\n",
      "Date:                Mon, 11 Apr 2022   Prob (F-statistic):              0.837\n",
      "Time:                        01:55:12   Log-Likelihood:                -16421.\n",
      "No. Observations:                1579   AIC:                         3.285e+04\n",
      "Df Residuals:                    1577   BIC:                         3.286e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   1755.9618    200.183      8.772      0.000    1363.309    2148.614\n",
      "PCA1          -4.7564     23.069     -0.206      0.837     -50.006      40.493\n",
      "==============================================================================\n",
      "Omnibus:                     4085.919   Durbin-Watson:                   2.021\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         62280123.652\n",
      "Skew:                          28.219   Prob(JB):                         0.00\n",
      "Kurtosis:                     974.309   Cond. No.                         8.68\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod4 = smf.ols(formula='Basket_Total_Price ~ PCA1 + 1', data=data)\n",
    "res4 = mod4.fit()\n",
    "print(res4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     Basket_Total_Price   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.001\n",
      "Method:                 Least Squares   F-statistic:                   0.06718\n",
      "Date:                Mon, 11 Apr 2022   Prob (F-statistic):              0.796\n",
      "Time:                        09:48:47   Log-Likelihood:                -16421.\n",
      "No. Observations:                1579   AIC:                         3.285e+04\n",
      "Df Residuals:                    1577   BIC:                         3.286e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   1755.9618    200.181      8.772      0.000    1363.313    2148.611\n",
      "PCA10         38.1394    147.151      0.259      0.796    -250.493     326.772\n",
      "==============================================================================\n",
      "Omnibus:                     4086.052   Durbin-Watson:                   2.021\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         62293494.832\n",
      "Skew:                          28.221   Prob(JB):                         0.00\n",
      "Kurtosis:                     974.413   Cond. No.                         1.36\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod5 = smf.ols(formula='Basket_Total_Price ~ PCA10 + 1', data=data)\n",
    "res5 = mod5.fit()\n",
    "print(res5.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
